{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":256618,"sourceType":"datasetVersion","datasetId":107620}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Working with Audio in Python**\n\nIn this project, we will provide a concise yet comprehensive tutorial on processing audio files and preparing them for machine learning applications. Audio data is a rich and complex source of information, widely used in domains like speech recognition, music classification, and sentiment analysis. This tutorial will guide you through the essential steps to analyze and extract features from audio files, enabling their use in machine learning models.\n\n![Audio Processing Visualization](https://t3.ftcdn.net/jpg/00/85/61/98/360_F_85619893_qcV9Vr8GQGGToKKozmKZlon9M1rNwWNd.jpg)\n\n---\n\n### **What You'll Learn:**\n1. **Understanding Audio as Data**:\n   - How audio is represented in the digital format (sample rate, amplitude, frequency).\n   - The fundamentals of waveform visualization and spectrograms.\n\n2. **Preprocessing Audio**:\n   - Techniques for loading audio data using libraries like `librosa`.\n   - Methods to trim, normalize, and resample audio files for consistency.\n\n3. **Feature Extraction**:\n   - Extracting meaningful features such as Mel Frequency Cepstral Coefficients (MFCCs), chroma features, and spectral contrast.\n   - Converting raw audio into numerical representations suitable for machine learning algorithms.\n\n4. **Building Machine Learning Models**:\n   - Using extracted features to train machine learning models to recognize patterns in audio.\n   - Implementing classifiers for tasks like speech emotion recognition or genre classification.\n\n---\n\n### **Why Process Audio Data for Machine Learning?**\nAudio data contains both temporal and frequency information, making it unique and challenging to work with. By transforming audio into numerical formats, such as spectrograms or MFCCs, we can leverage machine learning models to analyze, classify, and make predictions from audio inputs. This tutorial will help you bridge the gap between raw audio data and machine learning, empowering you to tackle a variety of audio-based projects.\n","metadata":{}},{"cell_type":"code","source":"# Data Manipulation and Analysis\nimport pandas as pd\nimport numpy as np\n\n# Visualization Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# File Handling\nfrom glob import glob\n\n# Audio Processing\nimport librosa\nimport librosa.display\n\n# Interactive Audio Playback\nimport IPython.display as ipd\n\n# Utility Functions\nfrom itertools import cycle\n\n# Set Plotting Theme\nsns.set_theme(style=\"white\", palette=None)\n\n# Define Color Palette and Cycle for Visualizations\ncolor_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\ncolor_cycle = cycle(color_pal)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T14:52:05.787447Z","iopub.execute_input":"2025-12-09T14:52:05.787772Z","iopub.status.idle":"2025-12-09T14:52:09.007366Z","shell.execute_reply.started":"2025-12-09T14:52:05.787739Z","shell.execute_reply":"2025-12-09T14:52:09.006255Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Key Concepts in Digital Audio**\n\nTo work effectively with audio in its digital form, it's important to understand several key concepts. These fundamental terms define how audio is represented, measured, and processed in digital systems. Below, we delve deeper into these concepts, providing detailed explanations and practical examples to help build a strong foundation.\n\n---\n\n### **1. Frequency (Hz)**  \n* **Definition**: Frequency represents the number of complete wave cycles that occur in one second. It determines the pitch of a sound. The unit of frequency is **Hertz (Hz)**.\n* **Key Insight**: \n  - High-frequency sounds have shorter wavelengths and are perceived as high-pitched (e.g., a whistle or a violin).\n  - Low-frequency sounds have longer wavelengths and are perceived as low-pitched (e.g., a drum or bass guitar).\n* **Real-Life Examples**:\n  - The typical human hearing range is **20 Hz to 20,000 Hz**.\n  - Speech frequencies generally range between **250 Hz and 8,000 Hz**.\n\n![Audio Frequency](https://www.physicsclassroom.com/Class/sound/u11l2a2.gif)  \n\n---\n\n### **2. Intensity (dB/Power)**  \n* **Definition**: Intensity measures the strength or power of a sound wave, represented by its amplitude. In audio processing, intensity is often expressed in **decibels (dB)**.\n* **Key Insight**: \n  - Larger amplitudes indicate louder sounds, while smaller amplitudes correspond to quieter sounds.\n  - Intensity is a logarithmic measure, meaning a small increase in decibels represents a significant change in perceived loudness.\n* **Real-Life Examples**:\n  - A whisper is around **30 dB**, normal conversation is about **60 dB**, and a rock concert can reach **110 dB or more**.\n  - Prolonged exposure to sounds above **85 dB** can cause hearing damage.\n\n![Audio Intensity](https://ars.els-cdn.com/content/image/3-s2.0-B9780124722804500162-f13-15-9780124722804.gif)  \n\n---\n\n### **3. Sample Rate**  \n* **Definition**: The sample rate specifies how frequently a digital system captures samples of an audio signal per second. It is measured in **Hertz (Hz)** or samples per second.\n* **Key Insight**: \n  - Higher sample rates capture more detail in the audio but result in larger file sizes.\n  - A sample rate must be at least **twice the highest frequency** in the audio to avoid aliasing, as dictated by the **Nyquist Theorem**.\n* **Common Sample Rates**:\n  - **44.1 kHz**: Used in CDs and many digital audio formats.\n  - **48 kHz**: Standard for professional audio and video production.\n  - **96 kHz and 192 kHz**: Used for high-resolution audio applications.\n\n![Audio Sample Rate](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ-3jLUxtdCN_YEUDZ1ZBcEUeHRAXCn_4imqg&s)  \n\n---\n\n### **Why These Concepts Matter**\n1. **Frequency, intensity, and sample rate** collectively define the quality and fidelity of digital audio.\n2. Understanding these concepts enables audio engineers and data scientists to effectively manipulate sound for various applications, such as speech recognition, music generation, and audio classification.\n3. By mastering these fundamentals, you can better analyze, process, and interpret audio data in both practical and theoretical contexts.\n","metadata":{}},{"cell_type":"markdown","source":"### **Reading Audio Files in Python**\n\nAudio files come in various formats, each with unique properties and use cases. Understanding these file types and how to read them is crucial for processing and analyzing audio data effectively. Below, we explore the common audio file formats and demonstrate how to load and handle them in Python.\n\n---\n\n### **Common Audio File Formats**\nHere are some widely used audio file formats and their characteristics:\n\n1. **MP3 (MPEG-1 Audio Layer III)**  \n   - **Use Case**: Popular for music and audio streaming due to its efficient compression.  \n   - **Advantages**: Small file size, widely supported across devices.  \n   - **Limitations**: Lossy compression reduces audio quality.  \n\n2. **WAV (Waveform Audio File Format)**  \n   - **Use Case**: Ideal for high-quality audio, often used in professional audio production.  \n   - **Advantages**: Uncompressed, retains high fidelity.  \n   - **Limitations**: Large file size, not as portable for online use.  \n\n3. **M4A (MPEG-4 Audio)**  \n   - **Use Case**: Common in Apple's ecosystem (e.g., iTunes).  \n   - **Advantages**: Compressed but retains high-quality audio.  \n   - **Limitations**: Limited compatibility with non-Apple devices.  \n\n4. **FLAC (Free Lossless Audio Codec)**  \n   - **Use Case**: Preferred for audiophiles and archival purposes.  \n   - **Advantages**: Lossless compression retains original quality with smaller file size than WAV.  \n   - **Limitations**: Larger file size compared to MP3.  \n\n5. **OGG (Ogg Vorbis)**  \n   - **Use Case**: Open-source alternative to MP3 for streaming.  \n   - **Advantages**: High-quality audio with better compression than MP3.  \n   - **Limitations**: Less compatibility with some devices and software.  \n","metadata":{}},{"cell_type":"code","source":"# Load in DataSet using glob\naudio_file = glob(\"/kaggle/input/ravdess-emotional-speech-audio/*/*.wav\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T14:52:09.009937Z","iopub.execute_input":"2025-12-09T14:52:09.010580Z","iopub.status.idle":"2025-12-09T14:52:09.145727Z","shell.execute_reply.started":"2025-12-09T14:52:09.010528Z","shell.execute_reply":"2025-12-09T14:52:09.144667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Play audio file\nipd.Audio(audio_file[5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T14:52:09.147261Z","iopub.execute_input":"2025-12-09T14:52:09.147716Z","iopub.status.idle":"2025-12-09T14:52:09.177246Z","shell.execute_reply.started":"2025-12-09T14:52:09.147665Z","shell.execute_reply":"2025-12-09T14:52:09.176093Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the audio file\n# `y` will contain the raw audio time-series data\n# `sr` will be the sample rate of the audio\ny, sr = librosa.load(audio_file[0])\n\n# Display the first 10 samples of the raw audio data\nprint(f\"First 10 samples of y: {y[:10]}\")\n\n# Display the shape of the audio data array\nprint(f\"Shape of y (audio data): {y.shape}\")\n\n# Display the sample rate of the audio\nprint(f\"Sample rate: {sr} Hz\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T14:52:09.178757Z","iopub.execute_input":"2025-12-09T14:52:09.179173Z","iopub.status.idle":"2025-12-09T14:52:24.284522Z","shell.execute_reply.started":"2025-12-09T14:52:09.179140Z","shell.execute_reply":"2025-12-09T14:52:24.283148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the raw audio waveform\npd.Series(y).plot(\n    figsize=(12, 7),             # Set the figure size for better visibility\n    lw=1,                       # Line width for the waveform\n    title=\"Raw Audio Waveform\", # Title of the plot\n    color=color_pal[0],         # Set the color using the predefined palette\n    xlabel=\"Sample Index\",      # Label for the x-axis\n    ylabel=\"Amplitude\"          # Label for the y-axis\n)\n\n# Display the plot\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T14:52:24.287716Z","iopub.execute_input":"2025-12-09T14:52:24.288443Z","iopub.status.idle":"2025-12-09T14:52:24.799586Z","shell.execute_reply.started":"2025-12-09T14:52:24.288402Z","shell.execute_reply":"2025-12-09T14:52:24.798385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot a trimmed section of the raw audio waveform\npd.Series(y[30000:31000]).plot(\n    figsize=(12, 7),               # Set figure size for better visibility\n    lw=1,                         # Line width for the waveform\n    title=\"Zoomed-In View of Raw Audio Waveform\",  # Descriptive title for clarity\n    color=color_pal[1],           # Use a consistent color palette for aesthetics\n    xlabel=\"Sample Index (Trimmed)\", # X-axis label indicating the zoomed-in range\n    ylabel=\"Amplitude\"            # Y-axis label for amplitude values\n)\n\n# Display the plot\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T14:52:24.801022Z","iopub.execute_input":"2025-12-09T14:52:24.801392Z","iopub.status.idle":"2025-12-09T14:52:25.178217Z","shell.execute_reply.started":"2025-12-09T14:52:24.801358Z","shell.execute_reply":"2025-12-09T14:52:25.177140Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Trim the audio signal to remove silence\n# `y_trim`: Audio data after silence trimming\n# `top_db`: Threshold in decibels for considering a region as silence\ny_trim, _ = librosa.effects.trim(y, top_db=35)\n\n# Plot the trimmed audio waveform\npd.Series(y_trim).plot(\n    figsize=(12, 7),                # Set figure size for clear visualization\n    lw=1,                          # Line width for the waveform\n    title=\"Trimmed Audio Waveform (Silence Removed)\",  # Descriptive title\n    color=color_pal[1],            # Use a specific color from the palette\n    xlabel=\"Sample Index (Trimmed)\", # Label the x-axis for context\n    ylabel=\"Amplitude\"             # Label the y-axis to indicate amplitude values\n)\n\n# Show the plot\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T14:52:25.179776Z","iopub.execute_input":"2025-12-09T14:52:25.180204Z","iopub.status.idle":"2025-12-09T14:52:27.351065Z","shell.execute_reply.started":"2025-12-09T14:52:25.180159Z","shell.execute_reply":"2025-12-09T14:52:27.349771Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **What is a Spectrogram?**\n\nA **spectrogram** is a visual representation of the spectrum of frequencies in a signal as it varies over time. It is widely used in audio analysis and signal processing to understand the frequency content of an audio signal. Spectrograms are especially useful in applications like speech recognition, music analysis, and machine learning tasks involving audio.\n\n---\n\n### **How It Works**\n1. **Input Signal**: The input is a time-domain signal, such as an audio waveform.\n2. **Short-Time Fourier Transform (STFT)**: The signal is divided into small, overlapping time segments (windows). A Fourier Transform is applied to each segment, converting it from the time domain to the frequency domain.\n3. **Frequency vs. Time Representation**:\n   - **X-Axis**: Represents time, showing how the signal evolves over time.\n   - **Y-Axis**: Represents frequency, showing the range of frequencies present at any given time.\n4. **Amplitude (Color)**:\n   - The intensity or amplitude of each frequency component is represented by color or brightness.\n   - **Brighter regions**: Higher amplitudes (louder or more dominant frequencies).\n   - **Darker regions**: Lower amplitudes (quieter or less dominant frequencies).\n\n---\n\n### **Key Components**\n- **Time (X-Axis)**: The horizontal axis represents the progression of the audio signal over time.\n- **Frequency (Y-Axis)**: The vertical axis shows the range of frequencies present in the signal, often plotted on a linear or logarithmic scale.\n- **Amplitude (Color)**: The color intensity represents the amplitude (power) of each frequency component.\n\n---\n\n### **Types of Spectrograms**\n1. **Linear Spectrogram**:\n   - Frequencies are displayed on a linear scale.\n   - Suitable for signals where all frequencies are equally important.\n2. **Logarithmic (Mel) Spectrogram**:\n   - Frequencies are displayed on a logarithmic scale, mimicking human perception.\n   - Often used in speech and music analysis.\n3. **Mel Spectrogram**:\n   - Frequencies are scaled based on the Mel scale, which aligns more closely with how humans perceive pitch.\n","metadata":{}},{"cell_type":"code","source":"# Compute the Short-Time Fourier Transform (STFT) of the audio signal\nD = librosa.stft(y)  # D is the complex-valued STFT matrix\n\n# Convert the STFT magnitudes to decibels (log scale)\nS_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)  \n# np.abs(D) ensures we take the magnitude of the STFT, discarding phase information.\n# ref=np.max normalizes the values relative to the maximum magnitude in the spectrogram.\n\n# Display the shape of the resulting spectrogram\nprint(f\"Spectrogram Shape: {S_db.shape}\")  # (n_freq_bins, n_time_frames)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the Log-Frequency Spectrogram\nfig, ax = plt.subplots(figsize=(12, 6))  # Larger figure for better visibility\n\n# Display the spectrogram with log-scaled frequency axis\nimg = librosa.display.specshow(\n    S_db,                 # Spectrogram data (in decibels)\n    x_axis='time',        # X-axis: Time in seconds\n    y_axis='log',         # Y-axis: Logarithmic frequency scale\n    sr=sr,                # Sample rate (ensures correct time and frequency scaling)\n    cmap='magma',         # Colormap for improved aesthetics\n    ax=ax                 # Subplot to plot on\n)\n\n# Add descriptive title and labels\nax.set_title(\"Log-Frequency Spectrogram (Decibel Scale)\", fontsize=18, fontweight='bold')\nax.set_xlabel(\"Time (s)\", fontsize=14)\nax.set_ylabel(\"Frequency (Hz)\", fontsize=14)\n\n# Add a color bar to indicate decibel levels\ncbar = fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\ncbar.set_label(\"Amplitude (dB)\", fontsize=12)\n\n# Show the plot\nplt.tight_layout()  # Adjust layout to prevent clipping\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Mel Spectrogram: A Human-Centric Representation of Audio**\n\nA **Mel Spectrogram** is a type of spectrogram where the frequency axis is scaled according to the **Mel scale**, which aligns closely with the way humans perceive sound and pitch. It is widely used in audio processing and machine learning, particularly in tasks like **speech recognition**, **music analysis**, and **audio classification**.\n\n---\n\n### **Key Concepts**\n\n1. **Spectrogram**:\n   - A visual representation of audio in the **time-frequency domain**.\n   - It shows how frequencies (y-axis) change over time (x-axis), with the intensity (color) representing the amplitude of each frequency component.\n\n2. **Mel Scale**:\n   - The Mel scale is a perceptual scale of pitches where equal distances correspond to perceived equal changes in pitch.\n   - Humans are more sensitive to lower frequencies than higher ones. The Mel scale compresses higher frequencies to better reflect this sensitivity.\n   - The conversion from frequency (Hz) to Mel scale is done using the formula:\n\n        ![Mel Scale Formula](https://latex.codecogs.com/png.latex?Mel(f)%20=%202595%20%5Ccdot%20%5Clog_{10}(1%20+%20%5Cfrac{f}{700}))\n\n3. **Mel Spectrogram**:\n   - A spectrogram where the frequencies are transformed into the Mel scale using **filter banks**.\n   - Instead of analyzing all frequency bins linearly, the Mel spectrogram groups frequencies into broader bands at higher frequencies.\n\n---\n\n### **How to Compute a Mel Spectrogram**\nThe process of generating a Mel spectrogram typically involves:\n1. **Short-Time Fourier Transform (STFT)**:\n   - Compute the STFT to convert the audio signal from the time domain to the frequency domain.\n2. **Apply Mel Filter Banks**:\n   - A set of overlapping triangular filters is applied to group the linear frequency bins into Mel-scaled frequency bins.\n3. **Convert Amplitudes to Decibels (Optional)**:\n   - Amplitudes are converted to the **logarithmic decibel scale** for better visualization and to match human loudness perception.\n","metadata":{}},{"cell_type":"code","source":"# Generate the Mel Spectrogram\n# y: Audio time series\n# sr: Sampling rate of the audio\n# n_mels: Number of Mel bands to generate (default is 128, here set to 256 for higher resolution)\nS = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=256)\n\n# Display the shape of the Mel Spectrogram\nprint(f\"Mel Spectrogram Shape: {S.shape}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert the Mel Spectrogram to Decibels (Logarithmic Scale)\nS_db_mel = librosa.amplitude_to_db(S, ref=np.max)\n\n# Display Information\nprint(f\"Mel Spectrogram (in dB) Shape: {S_db_mel.shape}\")\nprint(f\"Decibel Range: {S_db_mel.min():.2f} dB to {S_db_mel.max():.2f} dB\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the Log-Scaled Mel Spectrogram\nfig, ax = plt.subplots(figsize=(12, 7))  # Increase figure size for better clarity\n\n# Display the Mel Spectrogram in Decibels\nimg = librosa.display.specshow(\n    S_db_mel,               # Spectrogram data (in dB scale)\n    sr=sr,                  # Sampling rate for accurate time display\n    x_axis='time',          # X-axis: Time (seconds)\n    y_axis='mel',           # Y-axis: Mel-frequency scale\n    cmap='magma',           # Use a perceptually uniform colormap\n    ax=ax                   # Plot on the specified subplot\n)\n\n# Add Title and Axis Labels\nax.set_title(\"Mel Spectrogram (Log Scale in Decibels)\", fontsize=18, fontweight=\"bold\")\nax.set_xlabel(\"Time (s)\", fontsize=14)\nax.set_ylabel(\"Mel Frequency (Hz)\", fontsize=14)\n\n# Add a Color Bar to Show the Decibel Range\ncbar = fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\ncbar.set_label(\"Amplitude (dB)\", fontsize=12)\n\n# Adjust Layout for Better Visualization\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}